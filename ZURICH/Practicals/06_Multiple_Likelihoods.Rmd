---
title: "Models with multiple likelihoods"
subtitle: 'Day 2, Afternoon'
author: "Instructor: Sara Martino"
#date: "`r format(Sys.time(), '%d %B, %Y')`"
bibliography: biblio.bib  
output:
  html_document:
    toc: yes
    toc_float: yes
    #code_download: yes
    toc_depth: 3
    number_sections: true

---




```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "~/INLA_course/Practicals/")

knitr::opts_chunk$set(echo = TRUE,  
                      message=FALSE, 
                      warning=FALSE, 
                      strip.white=TRUE, 
                      prompt=FALSE,
                      fig.align="center",
                       out.width = "60%")

library(knitr)    # For knitting document and include_graphics function
```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'),
               color = 'darkred',
               tooltip_message = 'Click to copy', tooltip_success = 'Done')
```

---

Start by loading useful libraries:
```{r}
library(ggplot2)
library(INLA)
library(inlabru)
library(viridis)
library(tidyverse)
library(patchwork)
```

# Coregionalization model

In this practical we present a way to fit the Bayesian coregionalization model similar to the one  presented in Chapter 8 in Blangiardo and Cameletti (2015). 

These models are often used when measurement stations record several variables; for example, a station measuring pollution may register values of CO2 and NO2. Instead of modeling these as several univariate datasets, the models we present in this section deal with the joint dependency structure. Dependencies among the different outcomes are modeled through shared components at the predictor level.

Usually, in coregionalization models, the different responses are assumed to be observed at the same locations. With the INLA-SPDE approach, we do not require the different outcome variables to be measured at the same locations. Hence, in the code example below we show how to model responses observed at different locations. 

## The model
We consider the following model
$$
\begin{aligned}
y_1(s) & = \alpha_1 + z_1(s) + e_1(s)\\
y_2(s) & = \alpha_2 + \lambda\ z_1(s) + z_2(s) +e_1(s)
\end{aligned}
$$
where the $\alpha_k$ are intercepts,  $z_k(s)$ are Gaussian spatial effects and $e_k(s)$ are uncorrelated error terms, with $k=1,2$.
$\lambda$ is a weight for the spatial effect $z_1(s)$.


## Data simulation

We start by simulating  the data. We first define a function to sample from a Matern RF with given range and sd.
```{r}
rMatern <- function(n, coords, sigma=1, range, 
                    kappa = sqrt(8*nu)/range, 
                    variance = sigma^2, 
                    nu=1) {
  m <- as.matrix(dist(coords))
  m <- exp((1-nu)*log(2) + nu*log(kappa*m)-
             lgamma(nu))*besselK(m*kappa, nu)
  diag(m) <- 1
  return(drop(crossprod(chol(variance*m),
                        matrix(rnorm(nrow(coords)*n), ncol=n))))
}
```

We then define the true values of all parameters

```{r}
# Intercept on reparametrized model
alpha <- c(-5, 3) 
# Random field marginal variances
m.var <- c(0.5, 0.4) 
# GRF range parameters:
range <- c(4, 6)
# Copy parameters: reparameterization of coregionalization 
# parameters
lambda <- c(0.7) 
# Standard deviations of error terms
e.sd <- c(0.3, 0.2)

```

and simulate our data. We assume that we observe data in a window $(0:10)\times(0:5)$.
We assume that in some locations we observe both $y_1$ and $y_2$ while in other we only observe one of them

```{r}
# define the area of interest
p = Polygon(cbind(c(0,10,10,0,0),c(0,0,5,5,0)))
ps = Polygons(list(p),1)
sps = SpatialPolygons(list(ps))
# how many observation we have
n1 <- 99
n2 <- 100
n_common = 50
# simulate observation locations
loc0 <- cbind(runif(n_common) * 10, runif(n_common) * 5) 
loc1 <-  cbind(runif(n1-n_common) * 10, 
                          runif(n1-n_common) * 5)
loc2 <-  cbind(runif(n2-n_common) * 10, 
                          runif(n2-n_common) * 5) 

# simulate the two gaussian field at the locations
z1 <- rMatern(1, rbind(loc1, loc0, loc2), range = range[1],
                  sigma = sqrt(m.var[1]))

z2 <- rMatern(1, rbind(loc0, loc2), range = range[2],
                  sigma = sqrt(m.var[2]))

loc1 = rbind(loc1, loc0)
loc2 = rbind(loc0, loc2)

## create the linear predictors
eta1 = alpha[1] + z1[1:n1] 
eta2 = alpha[2] + lambda * z1[(n1-n_common) + 1:n2]  + z2

# simulate data by addint the obervation noise
y1 <- eta1 + rnorm(n1, 0, e.sd[1])
y2 <- eta2  + rnorm(n2, 0, e.sd[2])
# Create the two dataframes
df1 = data.frame(x = loc1[,1],
                 y = loc1[,2],
                 z  = y1)
df2 = data.frame(x = loc2[,1],
                 y = loc2[,2],
                 z  = y2)

```


We can  visualize the observations
```{r, out.width="95%"}
p1 = ggplot(data = df1) + geom_point(aes(x,y,color = z)) +
  scale_color_viridis()+ coord_equal() + xlab("") + ylab("") +
  gg(sps)
p2 = ggplot(data = df2) + geom_point(aes(x,y,color = z)) +
  scale_color_viridis() + coord_equal()+ xlab("") + ylab("")+
  gg(sps)
p1+p2+plot_layout(ncol = 1)
```
## Mesh definition

We need to define a mesh. We use the location observations and the area of interest as a starting point.
```{r}
mesh <- inla.mesh.2d(rbind(loc1, loc2), 
                    boundary = sps,
                     max.edge = c(0.5, 1.5), 
                     offset = c(0.1, 2.5), 
                     cutoff = 0.1)
```

Here is the mesh, together with the observation $y_1$ (red) and $y_2$ (black).
```{r, echo = F}
ggplot() + 
  gg(mesh) + 
  geom_point(data =  df1, aes(x,y), size = 2, color = "red") +
    geom_point(data =  df2, aes(x,y)) + xlab("") + ylab("")+
  gg(sps)
```

## SPDE definition

We need to define one `spde` object that contains information about priors for the range and the standard deviation.

Here we choose to use the same priors for borh ${\bf z}_1$ and ${\bf z}_2$ so we create only one `spde` object. 
```{r}
spde <- inla.spde2.pcmatern(
  mesh = mesh,
  prior.range = c(0.5, 0.01), # P(range < 0.5) = 0.01
  prior.sigma = c(1, 0.01)) # P(sigma > 1) = 0.01
```


## Run the model
```{r}
coordinates(df1) = c("x","y")
coordinates(df2) = c("x","y")

cmp = ~  Intercept1(1) + Intercept2(1) +
  z1(coordinates, model = spde) +
  z1_copy(coordinates, copy = "z1", fixed = FALSE) +
  z2(coordinates, model = spde)

lik1 = like(formula = z ~ Intercept1 + z1,
            family  = "gaussian",
            data = df1)

lik2 = like(formula = z ~ Intercept2 + z1_copy + z2,
            family = "gaussian",
            data = df2)


res = bru(cmp, lik1, lik2,
          options = list(verbose = F,
                         bru_max_iter = 1,
                         bru_verbose = 1,
                         inla.mode  = "experimental"))
```

## Model Results

<font size="5"> **Exercise 1:** </font> Check the model results and see that the model manages to recover the true value of the parameters. [Solution](#Solution1)



<font size="5"> **Exercise 2:** </font> Compute predictions from the model *at the observation points* and compare them with the observed values. [Solution](#Solution2)

<font size="5"> **Exercise 3:** </font> Plot the estimated posterior mean and standard deviation for the two Gaussian fields ${\bf z}_1$ and ${\bf z}_2$. [Solution](#Solution3)

```{r, echo = T, eval = F}
pxl = pixels(mesh)
pred_z1 = predict(res, pxl, ???)
pred_z2 = predict(res, pxl, ???)
```

```{r,echo = F, eval = T, out.width="100%"}
pxl = pixels(mesh)
pred_z1 = predict(res, pxl, ~ z1)
pred_z2 = predict(res, pxl, ~ z2 )

p1 = ggplot() + gg(pred_z1, aes(fill = mean)) + scale_fill_viridis() +
  ggtitle("Posterior mean for z1") + coord_equal() + xlab("") + ylab("")
p2 = ggplot() + gg(pred_z2, aes(fill = mean)) + scale_fill_viridis()+
  ggtitle("Posterior mean for z2")+ coord_equal() + xlab("") + ylab("")

p3 = ggplot() + gg(pred_z1, aes(fill = sd)) + scale_fill_viridis()+
  ggtitle("Posterior sd for z1")+ coord_equal()+ xlab("") + ylab("")
p4 = ggplot() + gg(pred_z2, aes(fill = sd)) + scale_fill_viridis()+
  ggtitle("Posterior sd for z2")+ coord_equal()+ xlab("") + ylab("")
p1 + p2 + p3 + p4

```

In the sd plot we see an increase of the variance along the border of the area. This is an consequence  of the boundary effect in the SPDE representation and is the reason why we need to have  a buffer area around the area of interest when creating the mesh.

To avoid predicting outside the area of interest we can use the option `mask=` in the `pixels()` function as
```{r}
pxl = pixels(mesh, mask = sps)
```


<font size="5"> **Exercise 4:** </font> Compute predictions from the model over the  area of interest. Plot the posterior mean and the posterior sd.  [Solution](#Solution4)




# Adding one covariate

We are now going to simulate data from a coregionalized model where one of the observations is dependent on a covariate.

The model is as following
$$
\begin{aligned}
y_1(s) & = \alpha_1 + z_1(s) + \beta\ x(s) +  e_1(s)\\
y_2(s) & = \alpha_2 + \lambda\ z_1(s)  +e_1(s)
\end{aligned}
$$
where $x(s)$ is a known covariate, $\beta$ the linear effect and the other elements are like before.


## Simulate data

We start by simulating the covariate in space
```{r}
func <- function (x, y) {
   return (cos(x /4) - sin(y /4) )
}
x = seq(-3,13,0.1)
y = seq(-3,8,0.1)
gg = expand.grid(x,y)
covariate = SpatialPixelsDataFrame(points = gg,
                                   data = data.frame(cov = func(gg[,1],gg[,2])))
ggplot() + gg(covariate) +
  scale_fill_viridis() + xlab("") + ylab("")
```


We now simulate the data. For simplicity we reuse the  locations and value of the ${\bf z}_1$ field we have generated earlier.
```{r}
## create the linear predictors
eta1 = alpha[1] + z1[1:n1] + 0.5 * func(loc1[,1],loc1[,2])
eta2 = alpha[2] + lambda * z1[(n1-n_common) + 1:n2]

# simulate data by addint the obervation noise
y1 <- eta1 + rnorm(n1, 0, e.sd[1])
y2 <- eta2  + rnorm(n2, 0, e.sd[2])
# Create the two dataframes
df1 = data.frame(x = loc1[,1],
                 y = loc1[,2],
                 cov = func(loc1[,1],loc1[,2]),
                 z  = y1)
df2 = data.frame(x = loc2[,1],
                 y = loc2[,2],
                 z  = y2)
coordinates(df1) = c("x","y")
coordinates(df2) = c("x","y")
```

```{r}
p1 = ggplot() + gg(df1, aes(color = z)) + 
  scale_color_viridis() + xlab("") + ylab("") +
  ggtitle("y1") + coord_equal()
p2 = ggplot() + gg(df2, aes(color = z)) + 
  scale_color_viridis() + xlab("") + ylab("")+
  ggtitle("y2") + coord_equal()

p1 + p2 + plot_layout(ncol = 1)
```

## Fit the model


<font size="5"> **Exercise 5:** </font> Create a mesh and a `spde` object.

<font size="5"> **Exercise 6:** </font> Fill in the code below to fit the model to the simulated data. [Solution](#Solution6)

```{r, echo = T, eval = F}

cmp = ~  ???

lik1 = like(formula = z ~ ???,
            family  = ???,
            data = df1)

lik2 = like(formula = z ~ ???,
            family = ???,
            data = df2)


res = bru(cmp, lik1, lik2,
          options = list(verbose = F,
                         bru_max_iter = 1,
                         bru_verbose = 1,
                         inla.mode  = "experimental"))
```

```{r, echo = F, eval = T}

cmp = ~  Intercept1(1) + Intercept2(1) +
  z1(coordinates, model = spde) +
  z1_copy(coordinates, copy = "z1", fixed = FALSE) +
  cov(covariate, model = "linear")

lik1 = like(formula = z ~ Intercept1 + z1 + cov,
            family  = "gaussian",
            data = df1)

lik2 = like(formula = z ~ Intercept2 + z1_copy,
            family = "gaussian",
            data = df2)


res = bru(cmp, lik1, lik2,
          options = list(verbose = F,
                         bru_max_iter = 1,
                         bru_verbose = 1,
                         inla.mode  = "experimental"))
```


<font size="5"> **Exercise 7:** </font> Use the function `generate()` to create 4 simulations from 
$\widetilde{\pi}({\bf z}_1|{\bf y}_1,{\bf y}_2) $ and $\widetilde{\pi}({\bf \eta}_1|{\bf y}_1,{\bf y}_2) $. 
[Solution](#Solution7)



---

# Solutions


## Exercise 1{#Solution1}

```{r, echo = T, eval = F}
#fixed effects
data.frame(true = alpha, res$summary.fixed[,c(1,3,5)])
#hyperparameters
data.frame(true = c(1/e.sd^2, range[1], sqrt(m.var[1]),
                          range[2], sqrt(m.var[2]),
                    lambda),
           res$summary.hyperpar[,c(1,3,5)])
```


## Exercise 2{#Solution2}

```{r, echo = T, eval = F}
pred1 = predict(res, df1, ~Intercept1 + z1)
pred2 = predict(res, df2, ~Intercept2 + z1_copy +z2)

p1 = ggplot() + geom_point(data = data.frame(pred1) , aes(z, mean)) +
  geom_errorbar(data = data.frame(pred1) ,aes(z, ymin = q0.025, ymax = q0.975)) +
  geom_abline(intercept = 0, slope = 1)

p2 = ggplot() +   geom_point(data = data.frame(pred2) , aes(z, mean)) +
  geom_errorbar(data = data.frame(pred2) ,aes(z, ymin = q0.025, ymax = q0.975)) +
  geom_abline(intercept = 0, slope = 1)
p1+p2
```

## Exercise 3{#Solution3}
```{r,echo = F, eval = T, out.width="100%"}
pxl = pixels(mesh)
pred_z1 = predict(res, pxl, ~ z1)
pred_z2 = predict(res, pxl, ~ z2 )
```

## Exercise 4{#Solution4}

```{r, echo =T, eval = F}
pxl = pixels(mesh, mask = sps)
pred1 = predict(res, pxl, ~Intercept1 + z1)
pred2 = predict(res, pxl, ~Intercept2 + z1_copy + z2 )


p1 = ggplot() + gg(pred1, aes(fill = mean)) + scale_fill_viridis() +
  ggtitle("Posterior mean for eta_1") + coord_equal() + xlab("") + ylab("")
p2 = ggplot() + gg(pred2, aes(fill = mean)) + scale_fill_viridis()+
  ggtitle("Posterior mean for eta_2")+ coord_equal()+ xlab("") + ylab("")

p3 = ggplot() + gg(pred1, aes(fill = sd)) + scale_fill_viridis()+
  ggtitle("Posterior sd for eta_1")+ coord_equal()+ xlab("") + ylab("")
p4 = ggplot() + gg(pred2, aes(fill = sd)) + scale_fill_viridis()+
  ggtitle("Posterior sd for eta_2")+ coord_equal()+ xlab("") + ylab("")
p1 + p2 + p3 + p3

```

## Exercise 6{#Solution6}

```{r, echo = T, eval = F}

cmp = ~  Intercept1(1) + Intercept2(1) +
  z1(coordinates, model = spde) +
  z1_copy(coordinates, copy = "z1", fixed = FALSE) +
  cov(covariate, model = "linear")

lik1 = like(formula = z ~ Intercept1 + z1 + cov,
            family  = "gaussian",
            data = df1)

lik2 = like(formula = z ~ Intercept2 + z1_copy,
            family = "gaussian",
            data = df2)


res = bru(cmp, lik1, lik2,
          options = list(verbose = F,
                         bru_max_iter = 1,
                         bru_verbose = 1,
                         inla.mode  = "experimental"))
```

## Exercise 7
```{r, echo = T, eval = F}

# Note that the function generate() and predict() can output more
# than one 
sample1 = generate(res, pxl, ~ data.frame(z1 = z1,
                                          eta1 = Intercept1 + z1 + cov,
                                          cov = cov,
                                          eta2 = Intercept2 + z1_copy),
                   n.samples = 5)
data.frame(x = coordinates(pxl)[,1],
           y = coordinates(pxl)[,2],
           z1 = sample1[[1]]) %>%
    pivot_longer(-c(x,y)) %>%
    ggplot() + geom_tile(aes(x,y,fill = value)) + 
    facet_wrap(.~name) + scale_fill_viridis()



p1 = data.frame(x = coordinates(pxl)[,1],
           y = coordinates(pxl)[,2],
           z1 = sapply(sample1, function(x) x$z1)) %>%
  pivot_longer(-c(x,y)) %>%
  ggplot() + geom_tile(aes(x,y,fill = value)) + 
  facet_wrap(.~name) + scale_fill_viridis()

p2 = data.frame(x = coordinates(pxl)[,1],
           y = coordinates(pxl)[,2],
           z1 = sapply(sample1, function(x) x$eta1)) %>%
  pivot_longer(-c(x,y)) %>%
  ggplot() + geom_tile(aes(x,y,fill = value)) + 
  facet_wrap(.~name) + scale_fill_viridis()

p1 + p2

```

